{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain 필요성\n",
    "\n",
    "- OpenAI API 직접 사용시 \n",
    "    - 사용자 질문 -> LLM 호출 -> 응답\n",
    "\n",
    "- 실제 서비스에서 필요한 기능\n",
    "    - PDF 문서 안에서 답 찾기\n",
    "    - DB 조회 후 결과 설명\n",
    "    - 이전 대화 기억\n",
    "    - 여러 단계 추론\n",
    "\n",
    "#### LangChain 핵심 개념\n",
    "- Chain : 여러 단계를 연결한 처리 흐름\n",
    "    - ex) 검색 + 요약 + 생성 같은 다단계 흐름 구성 가능\n",
    "- Prompt Template : 프롬프트를 템플릿화\n",
    "- Memory : 이전 대화 저장\n",
    "- Retriever (검색기)\n",
    "- Agent : LLM 이 스스로 도구를 선택하여 실행\n",
    "\n",
    "#### 활용 가능 분야\n",
    "- 문서기반 QA\n",
    "    - ex) 사내문서 QA 챗봇, PDF 기반 질의응답, 법률 문서 검색, 기술 매뉴얼 검색\n",
    "- 챗봇 시스템\n",
    "- 데이터 분석 AI\n",
    "- 에이전트 기반 자동화 시스템\n",
    "\n",
    "### RAG(Retrieval Augmented Generation)\n",
    "- 검색 증강 생성\n",
    "- 특정 자료(문서, PDF, DB 등)에 대해 질문에 답할 수 있다.\n",
    "- 2가지 방식 제공\n",
    "    - RAG Agent 방식 : Agent 를 이용해 여러번 검색이 가능하고 복잡한 질문 처리 가능\n",
    "    - Two-step RAG Chain : 단순한 형태 / 한 번 호출\n",
    "\n",
    "- 처리 단계\n",
    "    - 1) Indexing : 데이터를 어떤 소스로부터 가져와서 검색할 수 있도록 정리(PDF->텍스트 추출->분할->임베딩->벡터DB 저장장)\n",
    "    - 2) Retrieval and Generation : 실제 RAG가 동작하는 단계(사용자가 질문을 입력하면 인덱스에서 관련 데이터를 검색하고 그 데이터를 모델에 전달하여 답변을 생성)\n",
    "\n",
    "#### 정리\n",
    "- LLM 기반 기능을 체계적으로 사용할 수 있도록 제공되는 오픈소스 프레임워크\n",
    "- 외부 데이터 연결, 문서검색, 도구사용(API 호출), 멀티스텝 추론, 메모리 유지 대화 같은 복합적인 AI 애플리케이션 구조를 쉽게 만들 수 있도록 도와주는 도구\n",
    "\n",
    "<img src=\"https://xeblog.s3.ap-northeast-2.amazonaws.com/langchain_builder_9f58224358.jpg\" width=\"700\" height=\"604\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import bs4\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.13 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain_openai) (1.2.15)\n",
      "Requirement already satisfied: openai<3.0.0,>=2.20.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain_openai) (2.21.0)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain_openai)\n",
      "  Downloading tiktoken-0.12.0-cp314-cp314-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.7.6)\n",
      "Requirement already satisfied: packaging>=23.2.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (9.1.4)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.14.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.6.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.67.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.2.13->langchain_openai) (0.4.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain_openai)\n",
      "  Downloading regex-2026.2.19-cp314-cp314-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.13->langchain_openai) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from tqdm>4->openai<3.0.0,>=2.20.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
      "Downloading tiktoken-0.12.0-cp314-cp314-win_amd64.whl (921 kB)\n",
      "   ---------------------------------------- 0.0/921.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 921.1/921.1 kB 27.8 MB/s  0:00:00\n",
      "Downloading regex-2026.2.19-cp314-cp314-win_amd64.whl (280 kB)\n",
      "Installing collected packages: regex, tiktoken, langchain_openai\n",
      "\n",
      "   ---------------------------------------- 0/3 [regex]\n",
      "   -------------------------- ------------- 2/3 [langchain_openai]\n",
      "   -------------------------- ------------- 2/3 [langchain_openai]\n",
      "   ---------------------------------------- 3/3 [langchain_openai]\n",
      "\n",
      "Successfully installed langchain_openai-1.1.10 regex-2026.2.19 tiktoken-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\source\\pythonsource\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "# 랭체인에서 제공하는 로더 \n",
    "from langchain_community.document_loaders import YoutubeLoader, WebBaseLoader, PyPDFLoader \n",
    "\n",
    "# 임베딩 처리\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 문서 내용 임베딩\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# 모델 생성\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 메세지\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 프롬프트 작성\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "\n",
    "# 글을 쪼갤 때 사용하는 라이브러리\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Tools\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 크롤링\n",
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "# 방법 1\n",
    "# model = init_chat_model(model=\"gpt-4.1-mini\", temperature=0,max_tkes=500,timeout=60)\n",
    "# 방법2\n",
    "model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Langchain\n",
    "- 모델 호출\n",
    "    - 1) invoke() : 모델이 답변을 전체 생성 후 응답\n",
    "    - 2) stream() : 모델이 생성한 답변을 중간중간 응답(논문요약, 보고서 생성, 코드 생성, 긴 설명)\n",
    "    - 3) batch() : 여러 개 요청을 한 번에 처리(병렬 처리 가능 - 리뷰 100 개 요약, 문단 50개 번역..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사과는 영양가가 풍부한 과일로 여러 건강상의 이점을 제공합니다. 주요 효능은 다음과 같습니다:\\n\\n1. **풍부한 항산화제 함유**  \\n   사과에는 비타민 C, 플라보노이드, 폴리페놀 등 항산화제가 많이 들어 있어 체내 활성산소를 제거하고 세포 손상을 예방하는 데 도움을 줍니다.\\n\\n2. **소화기 건강 개선**  \\n   사과에 함유된 식이섬유(특히 펙틴)는 장내 유익균의 성장을 촉진하고 배변을 원활하게 하여 소화기 건강을 돕습니다.\\n\\n3. **심혈관 질환 위험 감소**  \\n   식이섬유와 항산화 물질이 혈중 콜레스테롤 수치를 낮추고 혈압을 조절해 심장병과 뇌졸중 예방에 도움을 줄 수 있습니다.\\n\\n4. **체중 관리**  \\n   낮은 칼로리와 높은 섬유질 덕분에 포만감을 유지시켜 과식을 방지하고 체중 조절에 유리합니다.\\n\\n5. **혈당 조절**  \\n   사과 속의 천천히 소화되는 섬유소가 혈당의 급격한 상승을 막아 당뇨병 관리에 도움이 됩니다.\\n\\n6. **뼈 건강 증진**  \\n   사과에 들어있는 비타민 C와 다양한 미네랄이 뼈의 밀도를 유지하고 골밀도 감소를 예방하는 데 기여할 수 있습니다.\\n\\n이 외에도 사과는 피로 회복, 면역력 강화 등에 긍정적인 영향을 주므로 꾸준히 섭취하는 것이 좋습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 383, 'prompt_tokens': 16, 'total_tokens': 399, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_a391f2cee0', 'id': 'chatcmpl-DD0PUzuqYRAoDF5PScpHTtiFBi7eb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019c92f7-5a8e-73b0-8f62-06c271201b41-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 16, 'output_tokens': 383, 'total_tokens': 399, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "{'input_tokens': 16, 'output_tokens': 383, 'total_tokens': 399, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "사과는 영양가가 풍부한 과일로 여러 건강상의 이점을 제공합니다. 주요 효능은 다음과 같습니다:\n",
      "\n",
      "1. **풍부한 항산화제 함유**  \n",
      "   사과에는 비타민 C, 플라보노이드, 폴리페놀 등 항산화제가 많이 들어 있어 체내 활성산소를 제거하고 세포 손상을 예방하는 데 도움을 줍니다.\n",
      "\n",
      "2. **소화기 건강 개선**  \n",
      "   사과에 함유된 식이섬유(특히 펙틴)는 장내 유익균의 성장을 촉진하고 배변을 원활하게 하여 소화기 건강을 돕습니다.\n",
      "\n",
      "3. **심혈관 질환 위험 감소**  \n",
      "   식이섬유와 항산화 물질이 혈중 콜레스테롤 수치를 낮추고 혈압을 조절해 심장병과 뇌졸중 예방에 도움을 줄 수 있습니다.\n",
      "\n",
      "4. **체중 관리**  \n",
      "   낮은 칼로리와 높은 섬유질 덕분에 포만감을 유지시켜 과식을 방지하고 체중 조절에 유리합니다.\n",
      "\n",
      "5. **혈당 조절**  \n",
      "   사과 속의 천천히 소화되는 섬유소가 혈당의 급격한 상승을 막아 당뇨병 관리에 도움이 됩니다.\n",
      "\n",
      "6. **뼈 건강 증진**  \n",
      "   사과에 들어있는 비타민 C와 다양한 미네랄이 뼈의 밀도를 유지하고 골밀도 감소를 예방하는 데 기여할 수 있습니다.\n",
      "\n",
      "이 외에도 사과는 피로 회복, 면역력 강화 등에 긍정적인 영향을 주므로 꾸준히 섭취하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 호출 : invoke()\n",
    "# 하나의 메시지 입력 시 \n",
    "res = model.invoke(\"사과의 효능을 설명해줘\")\n",
    "print(res)\n",
    "print(res.usage_metadata)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "사과의 효능 설명\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "사과는 맛도 좋고 건강에도 여러 가지 이점이 있는 과일입니다. 사과의 주요 효능을 간단히 설명드리면 다음과 같습니다:\n",
      "\n",
      "1. **풍부한 식이섬유**  \n",
      "   사과에는 펙틴이라는 수용성 식이섬유가 많이 들어 있어 장 건강에 도움을 주고 변비 예방에 효과적입니다. 또한 혈중 콜레스테롤 수치를 낮추는 데에도 도움을 줄 수 있습니다.\n",
      "\n",
      "2. **항산화 작용**  \n",
      "   사과에는 비타민 C, 퀘르세틴(quercetin), 폴리페놀 같은 항산화 물질이 포함되어 있어 체내 활성산소를 제거하고 세포 손상을 줄여줍니다. 이로 인해 노화 방지와 면역력 강화에 도움이 됩니다.\n",
      "\n",
      "3. **심혈관 건강 개선**  \n",
      "   사과의 식이섬유와 항산화 성분은 혈압을 낮추고 혈관을 보호하여 심장 질환 위험을 줄이는 데 기여합니다.\n",
      "\n",
      "4. **혈당 조절**  \n",
      "   사과 속의 식이섬유는 혈당의 급격한 상승을 막아 당뇨병 관리에 도움을 줄 수 있습니다.\n",
      "\n",
      "5. **체중 관리**  \n",
      "   낮은 칼로리에 포만감을 주는 사과는 다이어트 중간 간식으로 적합하며, 과식을 방지하는 데 도움을 줍니다.\n",
      "\n",
      "6. **소화 촉진 및 해독 작용**  \n",
      "   사과는 소화를 돕고 간 기능을 지원하여 체내 독소 배출에 긍정적인 영향을 줄 수 있습니다.\n",
      "\n",
      "이처럼 사과는 다양한 면에서 건강에 유익한 과일로, 꾸준히 섭취하면 전반적인 건강 증진에 큰 도움을 받을 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# stream() : 모델이 생성한 답변을 중간중간 응답\n",
    "agent = create_agent(model)\n",
    "\n",
    "# stream_mede = \"values\" : 현재 상태 전체\n",
    "# stream_mede = \"update\" : update 된 내용\n",
    "for step in agent.stream({\"messages\":[{\"role\":\"user\",\"content\":\"사과의 효능 설명\"}]}, stream_mode=\"values\"):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사과는 맛이 좋고 영양가가 풍부한 과일로 여러 가지 건강상 이점을 제공합니다. 사과의 주요 효능은 다음과 같습니다:\n",
      "\n",
      "1. **풍부한 식이섬유**  \n",
      "   사과에는 식이섬유가 많이 들어 있어 소화를 돕고 변비를 예방하며 장 건강을 개선하는 데 도움을 줍니다.\n",
      "\n",
      "2. **심장 건강 증진**  \n",
      "   사과에 포함된 폴리페놀과 플라보노이드 등의 항산화 물질은 혈압을 낮추고 나쁜 콜레스테롤(LDL)을 줄여 심혈관 질환 위험을 감소시킵니다.\n",
      "\n",
      "3. **체중 조절 도움**  \n",
      "   칼로리가 낮고 포만감을 주는 식이섬유가 많아 다이어트 시 간식으로 좋고 과식을 방지하는 데 도움을 줍니다.\n",
      "\n",
      "4. **혈당 조절**  \n",
      "   사과에 함유된 식이섬유가 혈당 상승을 완만하게 하여 당뇨 관리에 긍정적인 영향을 미칩니다.\n",
      "\n",
      "5. **항산화 효과**  \n",
      "   비타민 C와 다양한 식물 화학물질이 활성산소를 제거해 세포 손상을 줄이고 노화 방지에 도움을 줍니다.\n",
      "\n",
      "6. **뇌 건강**  \n",
      "   일부 연구에 따르면 사과의 항산화 성분이 뇌 기능 향상과 알츠하이머병 같은 신경 퇴행성 질환 예방에 도움이 될 수 있습니다.\n",
      "\n",
      "7. **면역력 강화**  \n",
      "   비타민과 미네랄이 풍부해 신체 면역 기능을 강화하는 데 기여합니다.\n",
      "\n",
      "이처럼 사과는 일상 식단에 쉽게 포함시킬 수 있으며, 건강 유지와 질병 예방에 다양한 도움을 줄 수 있는 과일입니다.\n",
      "바나나는 영양가가 풍부하고 다양한 건강 효능이 있는 과일입니다. 주요 효능은 다음과 같습니다:\n",
      "\n",
      "1. **에너지 공급**  \n",
      "   바나나는 탄수화물이 풍부해 빠른 에너지 공급원으로 좋습니다. 운동 전후 간식으로 적합합니다.\n",
      "\n",
      "2. **소화 개선**  \n",
      "   바나나에는 식이섬유가 많이 들어 있어 소화를 돕고 변비 예방에 효과적입니다.\n",
      "\n",
      "3. **심장 건강**  \n",
      "   칼륨 함량이 높아 혈압을 조절하고 심장 질환 위험을 줄이는 데 도움을 줍니다.\n",
      "\n",
      "4. **기분 개선 및 스트레스 완화**  \n",
      "   바나나에는 세로토닌 분비를 촉진하는 트립토판이 포함되어 있어 기분을 좋게 하고 스트레스 완화에 도움을 줄 수 있습니다.\n",
      "\n",
      "5. **면역력 강화**  \n",
      "   비타민 C와 항산화 물질이 면역 체계를 강화하는 데 기여합니다.\n",
      "\n",
      "6. **뼈 건강**  \n",
      "   바나나에 포함된 마그네슘과 칼슘이 뼈를 튼튼하게 하는 데 도움을 줍니다.\n",
      "\n",
      "이처럼 바나나는 맛도 좋고 건강에 유익한 다양한 성분을 함유한 과일입니다. 매일 적당량 섭취하면 건강 유지에 도움을 줄 수 있습니다.\n",
      "오렌지는 맛이 좋을 뿐만 아니라 건강에도 여러 가지 좋은 효능을 가지고 있습니다. 주요 효능은 다음과 같습니다:\n",
      "\n",
      "1. **면역력 강화**  \n",
      "   오렌지에는 비타민 C가 풍부하게 함유되어 있어 면역 체계를 강화하고 감기나 기타 감염병에 대한 저항력을 높여줍니다.\n",
      "\n",
      "2. **항산화 작용**  \n",
      "   비타민 C와 플라보노이드 같은 항산화 성분이 체내 유해 산소를 제거해 세포 손상을 방지하고 노화 예방에 도움을 줍니다.\n",
      "\n",
      "3. **피부 건강 개선**  \n",
      "   비타민 C는 피부 콜라겐 생성에 중요한 역할을 하여 피부 탄력을 유지하고 주름 개선에 도움을 줍니다.\n",
      "\n",
      "4. **심혈관 건강 증진**  \n",
      "   오렌지에 들어있는 식이섬유와 칼륨은 혈압을 조절하고 콜레스테롤 수치를 낮춰 심장 건강을 지켜줍니다.\n",
      "\n",
      "5. **소화 촉진**  \n",
      "   오렌지의 식이섬유는 장운동을 원활하게 하여 변비 예방과 소화 기능 개선에 도움을 줍니다.\n",
      "\n",
      "6. **체중 관리**  \n",
      "   칼로리가 낮고 포만감을 주는 식이섬유가 풍부해 다이어트 중에도 좋은 간식이 될 수 있습니다.\n",
      "\n",
      "이처럼 오렌지는 다양한 영양소가 포함되어 있어 꾸준히 섭취하면 전반적인 건강 증진에 도움이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# batch()\n",
    "inputs = [\n",
    "    \"사과의 효능 설명\",\n",
    "    \"바나나의 효능 설명\",\n",
    "    \"오렌지의 효능 설명\",\n",
    "]\n",
    "res = model.batch(inputs)\n",
    "for r in res:\n",
    "    print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Messages\n",
    "    - https://docs.langchain.com/oss/python/langchain/messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm doing well, thank you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "system_msg = SystemMessage(\"You're a helpful assistant.\")\n",
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "res = model.invoke([system_msg,human_msg])\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002년 FIFA 월드컵에서 가장 화제가 된 나라는 단연 대한민국입니다. 그 이유는 다음과 같습니다:\n",
      "\n",
      "1. **역대 최고 성적 달성**  \n",
      "   대한민국은 2002년 월드컵에서 사상 최초로 4강에 진출하는 쾌거를 이루었습니다. 이는 아시아 국가 중 최초로 이루어진 일이며, 월드컵 역사상 비유럽·남미권 국가가 4강에 오른 보기 드문 사례였습니다.\n",
      "\n",
      "2. **공식 개최국 및 공동 개최국의 역할**  \n",
      "   2002년 월드컵은 대한민국과 일본이 공동 개최한 첫 번째 월드컵이었고, 대한민국은 이 대회를 통해 축구 강국들과의 맞대결에서 강한 모습을 보여주었습니다. 특히 한일 월드컵 개최국이어서 국민적 관심과 열기가 매우 컸습니다.\n",
      "\n",
      "3. **잊지 못할 경기들과 극적인 승리**  \n",
      "   - 16강전에서 이탈리아를 2-1로 꺾고,  \n",
      "   - 8강전에서 스페인을 연장 승부끝에 5-3으로 이겨 승리하는 등, 당시 여러 강팀들을 연파하며 축구 팬들과 미디어의 주목을 받았습니다.  \n",
      "   이 과정에서 여러 논란과 판정 논란도 있었지만, 한국 축구의 저력과 열정을 보여준 경기라는 평가를 받았습니다.\n",
      "\n",
      "4. **대표 선수들의 활약**  \n",
      "   안정환, 홍명보, 박지성, 이영표, 최용수 등 뛰어난 선수들이 팀을 이끌었고, 특히 안정환의 ‘돌려차기 골’과 같은 명장면들이 기억에 남습니다.\n",
      "\n",
      "5. **국민적 열기와 축구 문화 발전**  \n",
      "   월드컵 기간 동안 전국에서 축구 열기가 폭발했으며, 축구에 대한 국민적 관심이 크게 높아졌습니다. 이후 한국 축구의 발전과 프로축구 리그(K리그) 성장에도 큰 영향을 끼쳤습니다.\n",
      "\n",
      "이와 같은 이유들로 2002년 월드컵에서 대한민국은 단순한 참가국 이상의 의미를 지니며 세계 축구사에 한 획을 그은 국가로 기록되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 메시지 리스트\n",
    "# https://docs.langchain.com/oss/python/langchain/models#invoke\n",
    "# 대화기록\n",
    "\n",
    "message =[\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"2002 월드컵에서 가장 화제가 된 나라가 어딜까?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\" : \"assistant\",\n",
    "            \"content\" : \"대한민국이 화제가 됨\"\n",
    "        },\n",
    "        {\n",
    "            \"role\" : \"user\",\n",
    "            \"content\" : \"그나라가 화제가 된 이유를 상세하게 설명해\"\n",
    "        },\n",
    "    ]\n",
    "\n",
    "res = model.invoke(message)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tools : 앞에서 했었던 function calling \n",
    "    - https://docs.langchain.com/oss/python/langchain/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "위,경도 37.566,126.9784\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "서울의 현재 기온은 12.1도이며, 날씨는 맑음(Weather code 0)입니다. 더 궁금한 점 있으시면 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "# 앞에서 했었던 function calling \n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(location,timezone):\n",
    "    # 아래의 string은 필수임\n",
    "    \"\"\"지역명을 이용해서 위도, 경도를 찾은 후 해당 날씨를 가져오기\"\"\"\n",
    "    # 날씨 api 호출 : 위도 경도를 알아야만 되는 api임\n",
    "    params = {\"name\":location,\"count\":1,\"language\":\"ko\"}\n",
    "    geo = requests.get(\"https://geocoding-api.open-meteo.com/v1/search\",params=params,timeout=30).json()\n",
    "    results = geo.get(\"results\")[0]\n",
    "    if not results:\n",
    "        return json.dumps({\"error\":f\"{location} 위치를 찾지 못했습니다\"})\n",
    "    lat, lon = results.get('latitude'), results.get('longitude')\n",
    "    print(f\"위,경도 {lat},{lon}\")\n",
    "\n",
    "\n",
    "    url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "\n",
    "    weather_params = {\n",
    "        \"latitude\":lat,\n",
    "        \"longitude\":lon,\n",
    "        \"current_weather\":\"true\",\n",
    "        \"timezone\":timezone\n",
    "    }\n",
    "    weather_result = requests.get(url,params=weather_params,timeout=30).json()\n",
    "    current_weather = weather_result.get('current_weather')\n",
    "    if not current_weather:\n",
    "        return json.dumps({\"error\":\" 날씨 데이터를 가져오지 못했습니다\"})\n",
    "    # 받은 결과 모델에게 돌려주기 위한 json 구조 설정\n",
    "    return json.dumps({\n",
    "        \"location\":location,\n",
    "        \"latitute\":lat,\n",
    "        \"longitude\":lon,\n",
    "        \"temperature_c\": current_weather.get(\"temperature\"),\n",
    "        \"windspeed_kmh\": current_weather.get(\"windspeed_kmh\"),\n",
    "        \"winddirection_deg\": current_weather.get(\"winddirection_deg\"),\n",
    "        \"weathercode\": current_weather.get(\"weathercode\"),\n",
    "        \"time\": current_weather.get(\"time\"),\n",
    "\n",
    "    })\n",
    "\n",
    "tools = [get_weather]\n",
    "\n",
    "agent = create_agent(model = model, tools=tools)\n",
    "res = agent.invoke({\"messages\":[{\"role\":\"user\",\"content\":\"Seoul 날씨 어때?\"}]})\n",
    "res['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain 을 사용한 RAG\n",
    "#### [실습 1] blog 를 기반으로 질의 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is task docomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_O1ROC3Dmk7wpK0WLQ8E7DUwz)\n",
      " Call ID: call_O1ROC3Dmk7wpK0WLQ8E7DUwz\n",
      "  Args:\n",
      "    query: task decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "('Source : {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\n\\nSource : {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.', [Document(id='d4133f9d-fc02-4253-9374-4013fab6bd22', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='b0364eb1-2ce9-4778-a7f3-61f8075d8497', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')])\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition refers to breaking down a complicated task into smaller, manageable subtasks or steps. It can be done in several ways:\n",
      "\n",
      "1. Using a large language model (LLM) with simple prompts like \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\n",
      "2. Using task-specific instructions, such as \"Write a story outline\" for a novel.\n",
      "3. With human inputs.\n",
      "\n",
      "This process helps in planning by understanding what each step involves and making the task easier to address. One common approach called Chain of Thought (CoT) prompts the model to \"think step by step,\" decomposing complex tasks into simpler ones. An extension called Tree of Thoughts explores multiple reasoning possibilities at each step and generates a tree structure of thoughts to enhance decision-making.\n",
      "\n",
      "In some advanced methods, task decomposition leverages external classical planners along with LLMs, translating problems into formal planning languages (like PDDL) and outsourcing long-term planning to specialized tools.\n",
      "\n",
      "Overall, task decomposition helps in organizing, planning, and solving complex problems more effectively by breaking them into simpler components.\n"
     ]
    }
   ],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    header_template={\n",
    "        \"User-Agent\": \"my-langchain-rag-app\"\n",
    "    },\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "# print(docs) 문서의 양이 크기에 분할 필요\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# 전체 문서를 위의 규칙에 맞추어서 자름\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 검색\n",
    "# 1) 임베딩 모델 생성\n",
    "# 이전처럼 직접적으로 임베딩을 위한 ai를 호출하지 않고 framwork 사용\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# 2) 문서의 벡터화 /벡터 DB 저장\n",
    "vector_store = FAISS.from_documents(all_splits,embeddings)\n",
    "\n",
    "@tool\n",
    "def retrieve_context(query):\n",
    "    \"\"\"사용자 질문을 받아 벡터 검색 수행 / 관련문서 2개 가져온 후 텍스트 형태로 반환\"\"\"\n",
    "    # 사용자의 질문 임베딩\n",
    "    retrieve_docs= vector_store.similarity_search(query,k=2)\n",
    "    serialized = \"\\n\\n\".join((f\"Source : {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "                for doc in retrieve_docs)\n",
    "    return serialized, retrieve_docs\n",
    "\n",
    "tools = [retrieve_context]\n",
    "prompt = \"\"\"\n",
    "You have access to a tool that retrieves context from a blog post.\n",
    "Use the tool to help answer user queries.\n",
    "\"\"\"\n",
    "agent = create_agent(model, tools, system_prompt=prompt)\n",
    "\n",
    "query = \"What is task docomposition?\"\n",
    "\n",
    "for step in agent.stream({\"messages\":[{\"role\":\"user\",\"content\":query}]}, stream_mode=\"values\"):\n",
    "    step['messages'][-1].pretty_print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습 2] PDF 기반 질의탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서 로드드\n",
    "pdf_path = \"./data/Summary of ChatGPTGPT-4 Research.pdf\"\n",
    "\n",
    "if not Path(pdf_path).exists():\n",
    "    raise FileNotFoundError(f\"PDF not fount : {pdf_path}\")\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 텍스트 분할\n",
    "# add_start_index : 자른 문서의 index 가 필요하다면 선택적으로 넣으면 된다.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Summary of ChatGPT/GPT-4 Research\n",
      "and Perspective Towards the Future of Large\n",
      "Language Models\n",
      "Yiheng Liu ∗1, Tianle Han ∗1, Siyuan Ma 1, Jiayue Zhang 1,\n",
      "Yuanyuan Yang1, Jiaming Tian 1, Hao He 1, Antong Li 2, Mengshen\n",
      "He1, Zhengliang Liu 3, Zihao Wu 3, Dajiang Zhu 4, Xiang Li 5, Ning\n",
      "Qiang1, Dingang Shen 6,7,8, Tianming Liu 3, and Bao Ge †1\n",
      "1School of Physics and Information Technology, Shaanxi Normal University, Xi’an\n",
      "710119 China\n",
      "2School of Life and Technology Biomedical-Engineering, Xi’an Jiaotong University,\n",
      "Xi’an 710049, China\n",
      "3School of Computing, The University of Georgia, Athens 30602, USA\n",
      "4Department of Computer Science and Engineering, The University of Texas at\n",
      "Arlington, Arlington 76019, USA\n",
      "5Department of Radiology, Massachusetts General Hospital and Harvard Medical\n",
      "School, Boston 02115, USA\n",
      "6School of Biomedical Engineering, ShanghaiTech University, Shanghai 201210,\n",
      "China\n",
      "7Shanghai United Imaging Intelligence Co., Ltd., Shanghai 200230, China' metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-04-05T00:33:07+00:00', 'author': '', 'keywords': '', 'moddate': '2023-04-05T00:33:07+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.14159265-2.6-1.40.21 (TeX Live 2020) kpathsea version 6.3.2', 'subject': '', 'title': '', 'trapped': '/False', 'source': './data/Summary of ChatGPTGPT-4 Research.pdf', 'total_pages': 35, 'page': 0, 'page_label': '1'}\n"
     ]
    }
   ],
   "source": [
    "print(all_splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 벡터 스토어 생성\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(all_splits,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 검색 tool 작성\n",
    "@tool\n",
    "def retrieve_context(query):\n",
    "    \"\"\"사용자 질문을 받아 벡터 검색 수행 / 관련문서 k개 가져온 후 텍스트 형태로 반환\"\"\"\n",
    "    # 사용자의 질문 임베딩\n",
    "    retrieve_docs= vector_store.similarity_search(query,k=4)\n",
    "    serialized = \"\\n\\n\".join((f\"Source : {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "                for doc in retrieve_docs)\n",
    "    return serialized, retrieve_docs\n",
    "\n",
    "tools = [retrieve_context]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 생성\n",
    "\n",
    "prompt = \"\"\"\n",
    "You have access to a tool that retrieves context from a PDF document.\n",
    "Use the tool when you need avidence from the PDF.\n",
    "\"\"\"\n",
    "agent = create_agent(model, tools, system_prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What can i use chatGPT?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "You can use ChatGPT for a wide range of purposes, including but not limited to:\n",
      "\n",
      "1. **Answering Questions:** Get explanations, facts, and detailed answers on numerous topics.\n",
      "2. **Creative Writing:** Help with writing stories, poems, scripts, or brainstorming ideas.\n",
      "3. **Learning and Education:** Assistance with understanding concepts, summarizing texts, or tutoring in various subjects.\n",
      "4. **Professional Assistance:** Drafting emails, reports, resumes, and generating professional content.\n",
      "5. **Coding Help:** Writing, debugging, and explaining code snippets in various programming languages.\n",
      "6. **Language Translation & Practice:** Translating languages or practicing foreign language conversations.\n",
      "7. **General Advice:** Offering suggestions on lifestyle, productivity, mental health tips, and more.\n",
      "8. **Entertainment:** Playing text-based games, generating quizzes, or having casual conversations.\n",
      "\n",
      "If you have a specific use case in mind, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# 6. 질문 던지기\n",
    "query = \"What can i use chatGPT?\"\n",
    "\n",
    "for step in agent.stream({\"messages\":[{\"role\":\"user\",\"content\":query}]}, stream_mode=\"values\"):\n",
    "    step['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습 3] 유튜브 영상 자막 추출 후 내용요약\n",
    "\n",
    "- YoutubeLoader 를 이용한 자막 추출\n",
    "- RecursiveCharacterTextSplitter 를 이용한 일정한 크기로 자막 분할\n",
    "- agent 를 이용한 LLM 호출 \n",
    "- 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 유튜브 자막 로드\n",
    "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=Pn-W41hC764\")\n",
    "transcript = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 분할\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3. Map 단계 (각 chunk 요약)\n",
    "# -----------------------\n",
    "map_prompt= ChatPromptTemplate.from_template(\"\"\"\n",
    "Summerize the following transcript chunk:\n",
    "    ```{text}```\n",
    "Chunk summery                                            \n",
    "\"\"\")\n",
    "map_chain = (map_prompt | model | StrOutputParser())\n",
    "\n",
    "# chunk 요약\n",
    "chunk_summaries = []\n",
    "for doc in all_splits:\n",
    "    summary = map_chain.invoke({\"text\":doc.page_content})\n",
    "    chunk_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연설자는 초지능 기계 지능이 고용에 미치는 영향에 대해 기술 혁명이 직업에 큰 변화를 가져오지만 궁극적으로는 더 많고 나은 일자리가 생길 것이라고 전망한다. GPT-4는 자율적 존재가 아닌 도구로서 기존 업무를 보조하며 완전 대체보다는 역할 변화를 가져온다고 설명했다. 기술 발전은 인간의 삶의 질을 높이고 더 도전적이며 만족스러운 일을 추구하도록 만든다고 강조하며, AI와 자동화가 일자리에 미칠 영향에 대응하기 위해 정부 주도의 협력이 필요하다고 밝혔다. IBM의 몽고메리 씨는 AI가 모든 직업을 변화시키고 새로운 직업을 창출할 것이라며, 미래 인력을 AI와 협업할 수 있도록 준비하는 것이 중요하다고 말했다. IBM은 스킬빌드 플랫폼을 통해 7백만 명의 학습자와 1천 개 이상의 강좌를 제공하며 2030년까지 3천만 명을 대상으로 미래 역량 교육을 진행 중이다. AI 모델의 투명성과 과학자의 참여가 필수적이며, 데이터 이해와 평가가 중요하다고 언급했다. AGI가 도달하면 수십 년 내에 노동시장에 깊은 영향을 미칠 수 있으나, 현재 AI는 초기 단계로 향후 발전 가능성이 크다는 점도 함께 강조했다. 마지막으로, 기술 산업이 세상에 끼칠 수 있는 심각한 위험을 인지하고 이를 막기 위한 노력과 협력이 반드시 필요하다는 점을 강조하며 낙관적인 미래를 기대했다.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------\n",
    "# 4. Reduce 단계 (전체 결합 요약)\n",
    "# -----------------------\n",
    "\n",
    "combine_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You're given summaries of a YouTube's transcript.\n",
    "Combine them into a final Korean Summary. \n",
    "8~10 문장으로 요약하되 핵심문장, 근거, 예시, 결론을 포함해\n",
    "\n",
    "Summary\n",
    "```{text}```\n",
    "Final summary (Korean)                                                                                                                                                                                                                                                        \n",
    "\"\"\")\n",
    "\n",
    "combine_chain = (combine_prompt | model | StrOutputParser())\n",
    "\n",
    "final_summary = combine_chain.invoke({\"text\":\"\\n\\n\".join(chunk_summaries)})\n",
    "\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firecrawl\n",
    "- 웹사이트를 크롤링하여 LLM(Long Library Management)에서 사용할 수 있는 데이터로 변환\n",
    "- 접근 가능한 모든 하위 페이지를 크롤링하고 각 페이지에 대한 깔끔한 마크다운과 메타데이터를 제공\n",
    "- https://docs.langchain.com/oss/python/integrations/document_loaders/firecrawl (api 키 발급 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting firecrawl-py\n",
      "  Downloading firecrawl_py-4.16.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: requests in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (2.32.5)\n",
      "Requirement already satisfied: httpx in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (1.2.1)\n",
      "Requirement already satisfied: websockets in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (16.0)\n",
      "Requirement already satisfied: nest-asyncio in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (2.12.5)\n",
      "Requirement already satisfied: aiohttp in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from firecrawl-py) (3.13.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic>=2.0->firecrawl-py) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic>=2.0->firecrawl-py) (2.41.5)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic>=2.0->firecrawl-py) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from pydantic>=2.0->firecrawl-py) (0.4.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from aiohttp->firecrawl-py) (1.22.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->firecrawl-py) (3.11)\n",
      "Requirement already satisfied: anyio in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx->firecrawl-py) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx->firecrawl-py) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpx->firecrawl-py) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from httpcore==1.*->httpx->firecrawl-py) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from requests->firecrawl-py) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\source\\pythonsource\\.venv\\Lib\\site-packages (from requests->firecrawl-py) (2.6.3)\n",
      "Downloading firecrawl_py-4.16.2-py3-none-any.whl (212 kB)\n",
      "Installing collected packages: firecrawl-py\n",
      "Successfully installed firecrawl-py-4.16.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 26.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install firecrawl-py\n",
    "from firecrawl import Firecrawl\n",
    "app = Firecrawl(api_key=\"\")\n",
    "\n",
    "# Scrape a website\n",
    "app.scrape(\"firecrawl.dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# mode = scrape : 지정된 url 페이지 내용 가져오기 == WebBaseLoader()\n",
    "# mode = crawl : 하위 페이지 내용 크롤링\n",
    "loader = FireCrawlLoader(url=\"firecrawl.dev\", mode=\"scrape\")\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n",
    "loader = FireCrawlLoader(url=\"https://naver.com\", mode=\"crawl\",params={\"limit\":5})\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습] react 페이지 크롤링 후 크롤링 문서 기반으로 RAG 적용\n",
    "- 1. Ingest(색인) 단계: URL들 → Firecrawl → Document → Split → Embedding → FAISS 저장\n",
    "- 2. Query(질의) 단계: 질문 → FAISS 검색(top-k) → (질문 + 근거) → LLM 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "loader = FireCrawlLoader(\n",
    "    url=\"https://ko.react.dev/reference/react/\",\n",
    "    mode=\"crawl\",\n",
    "    params={\n",
    "        \"includePaths\": [r\"^/reference/react/use.*\"], \n",
    "        \"limit\": 100,  # 넓게 크롤링\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "print(len(docs))\n",
    "\n",
    "def get_url(doc):\n",
    "    md = doc.metadata or {}\n",
    "    return md.get(\"source_url\") or md.get(\"source\") or md.get(\"url\") or \"(unknown)\"\n",
    "\n",
    "\n",
    "# use~ 시작하는 url 만 걸러내기\n",
    "pattern = re.compile(r\"^https://ko\\.react\\.dev/reference/react/use.*\")\n",
    "use_docs = [d for d in docs if pattern.match(get_url(d))]\n",
    "\n",
    "print(len(use_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "UseCallback 에 대해서 설명해\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (call_vkreKzRZkwqWOojrV6UmMgir)\n",
      " Call ID: call_vkreKzRZkwqWOojrV6UmMgir\n",
      "  Args:\n",
      "    query: UseCallback 설명\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "Source : https://ko.react.dev/reference/react/useCallback\n",
      "Content: #### 주의 사항 [Link for 주의 사항 ](https://ko.react.dev/reference/react/useCallback\\#caveats \"Link for 주의 사항 \")\n",
      "\n",
      "- `useCallback`은 Hook이므로, **컴포넌트의 최상위 레벨** 또는 커스텀 Hook에서만 호출할 수 있습니다. 반복문이나 조건문 내에서 호출할 수 없습니다. 이 작업이 필요하다면 새로운 컴포넌트로 분리해서 state를 새 컴포넌트로 옮기세요.\n",
      "- React는 **특별한 이유가 없는 한 캐시 된 함수를 삭제하지 않습니다.** 예를 들어 개발 환경에서는 컴포넌트 파일을 편집할 때 React가 캐시를 삭제합니다. 개발 환경과 프로덕션 환경 모두에서, 초기 마운트 중에 컴포넌트가 일시 중단되면 React는 캐시를 삭제합니다. 앞으로 React는 캐시 삭제를 활용하는 더 많은 기능을 추가할 수 있습니다. 예를 들어, React에 가상화된 목록에 대한 빌트인 지원이 추가한다면, 가상화된 테이블 뷰포트에서 스크롤 밖의 항목에 대해 캐시를 삭제하는것이 적절할 것 입니다. 이는 `useCallback`을 성능 최적화 방법으로 의존하는 경우에 개발자의 예상과 일치해야 합니다. 그렇지 않다면 [state 변수](https://ko.react.dev/reference/react/useState#im-trying-to-set-state-to-a-function-but-it-gets-called-instead) 나 [ref](https://ko.react.dev/reference/react/useRef#avoiding-recreating-the-ref-contents) 가 더 적절할 수 있습니다.\n",
      "\n",
      "* * *\n",
      "\n",
      "## 용법 [Link for 용법 ](https://ko.react.dev/reference/react/useCallback\\#usage \"Link for 용법 \")\n",
      "\n",
      "Source : https://ko.react.dev/reference/react/useCallback\n",
      "Content: - [컴포넌트가 렌더링 될 때마다 `useCallback`이 다른 함수를 반환합니다.](https://ko.react.dev/reference/react/useCallback#every-time-my-component-renders-usecallback-returns-a-different-function)\n",
      "  - [반복문에서 각 항목마다 `useCallback`을 호출하고 싶지만, 이는 허용되지 않습니다.](https://ko.react.dev/reference/react/useCallback#i-need-to-call-usememo-for-each-list-item-in-a-loop-but-its-not-allowed)\n",
      "\n",
      "Source : https://ko.react.dev/reference/react/useCallback\n",
      "Content: `useCallback`으로 함수를 캐싱하는 것은 몇 가지 경우에만 가치 있습니다.\n",
      "\n",
      "- [`memo`](https://ko.react.dev/reference/react/memo) 로 감싸진 컴포넌트에 prop으로 넘깁니다. 이 값이 변하지 않으면 리렌더링을 건너뛰고 싶습니다. memoization은 의존성이 변했을 때만 컴포넌트가 리렌더링하도록 합니다.\n",
      "- 넘긴 함수가 나중에 어떤 Hook의 의존성으로 사용됩니다. 예를 들어, `useCallback`으로 감싸진 다른 함수가 이 함수에 의존하거나, [`useEffect`](https://ko.react.dev/reference/react/useEffect) 에서 이 함수에 의존합니다.\n",
      "\n",
      "다른 경우에서 `useCallback`으로 함수를 감싸는 것은 아무런 이익이 없습니다. 또한 이렇게 하는 것이 큰 불이익을 가져오지도 않으므로 일부 팀은 개별적인 경우를 따로 생각하지 않고, 가능한 한 많이 memoization하는 방식을 택합니다. 단점은 코드의 가독성이 떨어지는 것입니다. 또한, 모든 memoization이 효과적인 것은 아닙니다. “항상 새로운” 하나의 값이 있다면 전체 컴포넌트의 memoization을 깨기에 충분합니다.\n",
      "\n",
      "`useCallback`이 함수의 _생성_ 을 막지 않는다는 점을 주의하세요. 항상 함수를 생성하지만 (이건 괜찮습니다!), 그러나 React는 변경이 없는 경우에는 무시하고 캐시된 함수를 반환합니다\n",
      "\n",
      "**실제로 몇 가지 원칙을 따르면 많은 memoization을 불필요하게 만들 수 있습니다.**\n",
      "\n",
      "Source : https://ko.react.dev/reference/react/useCallback\n",
      "Content: - [레퍼런스](https://ko.react.dev/reference/react/useCallback#reference)\n",
      "  - [`useCallback(fn, dependencies)`](https://ko.react.dev/reference/react/useCallback#usecallback)\n",
      "- [용법](https://ko.react.dev/reference/react/useCallback#usage)\n",
      "  - [컴포넌트의 리렌더링 건너뛰기](https://ko.react.dev/reference/react/useCallback#skipping-re-rendering-of-components)\n",
      "  - [Memoized 콜백에서 상태 업데이트하기](https://ko.react.dev/reference/react/useCallback#updating-state-from-a-memoized-callback)\n",
      "  - [Effect가 너무 자주 실행되는 것을 방지하기](https://ko.react.dev/reference/react/useCallback#preventing-an-effect-from-firing-too-often)\n",
      "  - [커스텀 Hook 최적화하기](https://ko.react.dev/reference/react/useCallback#optimizing-a-custom-hook)\n",
      "- [문제 해결](https://ko.react.dev/reference/react/useCallback#troubleshooting)\n",
      "  - [컴포넌트가 렌더링 될 때마다 `useCallback`이 다른 함수를 반환합니다.](https://ko.react.dev/reference/react/useCallback#every-time-my-component-renders-usecallback-returns-a-different-function)\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "- `useCallback`은 React Hook으로, 함수를 메모이제이션(memoization)하여 동일한 함수 참조를 재사용할 수 있게 도와줍니다.\n",
      "- 주로 자식 컴포넌트에 props로 함수를 넘길 때, 불필요한 리렌더링을 방지하기 위해 사용합니다. 예를 들어, `memo`로 감싸진 컴포넌트에 넘길 때 유용합니다.\n",
      "- 또한, 다른 Hook의 의존성 배열에 함수를 넣어야 할 때 `useCallback`을 사용해 함수를 안정적으로 유지할 수 있습니다.\n",
      "- `useCallback(fn, dependencies)` 형태로 사용하고 의존성 배열이 바뀔 때만 새로운 함수를 생성합니다.\n",
      "- 컴포넌트 최상위 레벨이나 커스텀 Hook 내에서만 호출해야 하며, 반복문이나 조건문 내에서는 호출할 수 없습니다.\n",
      "- `useCallback`이 함수 생성을 막는 것이 아니라, 새로 생성된 함수가 변경되지 않은 경우 React가 이전 함수를 캐싱해 재사용한다는 점을 주의해야 합니다.\n",
      "- 성능 최적화를 위한 수단이지만, 모든 함수에 무조건 쓰는 것은 오히려 코드 가독성을 떨어뜨릴 수 있으니 적절히 사용해야 합니다.\n",
      "\n",
      "출처:\n",
      "- https://ko.react.dev/reference/react/useCallback\n",
      "- https://ko.react.dev/reference/react/useCallback#usage\n",
      "- https://ko.react.dev/reference/react/useCallback#caveats\n"
     ]
    }
   ],
   "source": [
    "# 벡터 작업\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(all_splits,embeddings)\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query):\n",
    "    \"\"\"URL 로 수집된 정보를 기반으로 사용자 질문을 받아 벡터 검색 수행 /\n",
    "      관련문서 k개 가져온 후 텍스트 형태로 반환\"\"\"\n",
    "    # 사용자의 질문 임베딩\n",
    "    retrieve_docs= vector_store.similarity_search(query,k=4)\n",
    "    serialized = \"\\n\\n\".join((f\"Source : {get_url(doc)}\\nContent: {doc.page_content}\")\n",
    "                for doc in retrieve_docs)\n",
    "    return serialized, retrieve_docs\n",
    "\n",
    "tools = [retrieve_context]\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "넌 React 공식 문서를 기반으로 답변하는 도우미야.\n",
    "공식문서 안에서만 대답해. 모르면 모른다고 말해.\n",
    "답변은 한국어로, 핵심을 불릿으로 정리하고 마지막에 출처 URL  나열해.\n",
    "\"\"\"\n",
    "agent = create_agent(model, tools, system_prompt=prompt)\n",
    "\n",
    "query = \"UseCallback 에 대해서 설명해\"\n",
    "\n",
    "for step in agent.stream({\"messages\":[{\"role\":\"user\",\"content\":query}]}, stream_mode=\"values\"):\n",
    "    step['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
