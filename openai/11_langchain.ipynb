{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain 필요성\n",
    "\n",
    "- OpenAI API 직접 사용시 \n",
    "    - 사용자 질문 -> LLM 호출 -> 응답\n",
    "\n",
    "- 실제 서비스에서 필요한 기능\n",
    "    - PDF 문서 안에서 답 찾기\n",
    "    - DB 조회 후 결과 설명\n",
    "    - 이전 대화 기억\n",
    "    - 여러 단계 추론\n",
    "\n",
    "#### LangChain 핵심 개념\n",
    "- Chain : 여러 단계를 연결한 처리 흐름\n",
    "    - ex) 검색 + 요약 + 생성 같은 다단계 흐름 구성 가능\n",
    "- Prompt Template : 프롬프트를 템플릿화\n",
    "- Memory : 이전 대화 저장\n",
    "- Retriever (검색기)\n",
    "- Agent : LLM 이 스스로 도구를 선택하여 실행\n",
    "\n",
    "#### 활용 가능 분야\n",
    "- 문서기반 QA\n",
    "    - ex) 사내문서 QA 챗봇, PDF 기반 질의응답, 법률 문서 검색, 기술 매뉴얼 검색\n",
    "- 챗봇 시스템\n",
    "- 데이터 분석 AI\n",
    "- 에이전트 기반 자동화 시스템\n",
    "\n",
    "### RAG(Retrieval Augmented Generation)\n",
    "- 검색 증강 생성\n",
    "- 특정 자료(문서, PDF, DB 등)에 대해 질문에 답할 수 있다.\n",
    "- 2가지 방식 제공\n",
    "    - RAG Agent 방식 : Agent 를 이용해 여러번 검색이 가능하고 복잡한 질문 처리 가능\n",
    "    - Two-step RAG Chain : 단순한 형태 / 한 번 호출\n",
    "\n",
    "- 처리 단계\n",
    "    - 1) Indexing : 데이터를 어떤 소스로부터 가져와서 검색할 수 있도록 정리(PDF->텍스트 추출->분할->임베딩->벡터DB 저장장)\n",
    "    - 2) Retrieval and Generation : 실제 RAG가 동작하는 단계(사용자가 질문을 입력하면 인덱스에서 관련 데이터를 검색하고 그 데이터를 모델에 전달하여 답변을 생성)\n",
    "\n",
    "#### 정리\n",
    "- LLM 기반 기능을 체계적으로 사용할 수 있도록 제공되는 오픈소스 프레임워크\n",
    "- 외부 데이터 연결, 문서검색, 도구사용(API 호출), 멀티스텝 추론, 메모리 유지 대화 같은 복합적인 AI 애플리케이션 구조를 쉽게 만들 수 있도록 도와주는 도구\n",
    "\n",
    "<img src=\"https://xeblog.s3.ap-northeast-2.amazonaws.com/langchain_builder_9f58224358.jpg\" width=\"700\" height=\"604\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import bs4\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랭체인에서 제공하는 로더 \n",
    "from langchain_community.document_loaders import YoutubeLoader, WebBaseLoader, PyPDFLoader \n",
    "\n",
    "# 임베딩 처리\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# 문서 내용 임베딩\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "# 모델 생성\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 메세지\n",
    "from langchain.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# 프롬프트 작성\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "\n",
    "# 글을 쪼갤 때 사용하는 라이브러리\n",
    "from langchain_text_splitters  import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Tools\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# 크롤링\n",
    "from langchain_community.document_loaders.firecrawl import FireCrawlLoader\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Langchain\n",
    "- 모델 호출\n",
    "    - 1) invoke() : 모델이 답변을 전체 생성 후 응답\n",
    "    - 2) stream() : 모델이 생성한 답변을 중간중간 응답(논문요약, 보고서 생성, 코드 생성, 긴 설명)\n",
    "    - 3) batch() : 여러 개 요청을 한 번에 처리(병렬 처리 가능 - 리뷰 100 개 요약, 문단 50개 번역..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 호출 : invoke()\n",
    "# 하나의 메시지 입력 시 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Messages\n",
    "    - https://docs.langchain.com/oss/python/langchain/messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 개의 메시지 리스트\n",
    "# https://docs.langchain.com/oss/python/langchain/models#invoke\n",
    "# 대화기록\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tools : 앞에서 했었던 function calling \n",
    "    - https://docs.langchain.com/oss/python/langchain/tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞에서 했었던 function calling \n",
    "import json\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain 을 사용한 RAG\n",
    "#### [실습 1] blog 를 기반으로 질의 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    header_template={\n",
    "        \"User-Agent\": \"my-langchain-rag-app\"\n",
    "    },\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습 2] PDF 기반 질의탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 문서 로드드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 텍스트 분할\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 벡터 스토어 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 검색 tool 작성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 질문 던지기\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습 3] 유튜브 영상 자막 추출 후 내용요약\n",
    "\n",
    "- YoutubeLoader 를 이용한 자막 추출\n",
    "- RecursiveCharacterTextSplitter 를 이용한 일정한 크기로 자막 분할\n",
    "- agent 를 이용한 LLM 호출 \n",
    "- 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 유튜브 자막 로드\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 문서 분할\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 3. Map 단계 (각 chunk 요약)\n",
    "# -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 4. Reduce 단계 (전체 결합 요약)\n",
    "# -----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Firecrawl\n",
    "- 웹사이트를 크롤링하여 LLM(Long Library Management)에서 사용할 수 있는 데이터로 변환\n",
    "- 접근 가능한 모든 하위 페이지를 크롤링하고 각 페이지에 대한 깔끔한 마크다운과 메타데이터를 제공\n",
    "- https://docs.langchain.com/oss/python/integrations/document_loaders/firecrawl (api 키 발급 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [실습] react 페이지 크롤링 후 크롤링 문서 기반으로 RAG 적용\n",
    "- 1. Ingest(색인) 단계: URL들 → Firecrawl → Document → Split → Embedding → FAISS 저장\n",
    "- 2. Query(질의) 단계: 질문 → FAISS 검색(top-k) → (질문 + 근거) → LLM 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "loader = FireCrawlLoader(\n",
    "    url=\"https://ko.react.dev/reference/react/\",\n",
    "    mode=\"crawl\",\n",
    "    params={\n",
    "        \"includePaths\": [r\"^/reference/react/use.*\"], \n",
    "        \"limit\": 100,  # 넓게 크롤링\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "def get_url(doc):\n",
    "    md = doc.metadata or {}\n",
    "    return md.get(\"source_url\") or md.get(\"source\") or md.get(\"url\") or \"(unknown)\"\n",
    "\n",
    "\n",
    "# use~ 시작하는 url 만 걸러내기\n",
    "pattern = re.compile(r\"^https://ko\\.react\\.dev/reference/react/use.*\")\n",
    "use_docs = [d for d in docs if pattern.match(get_url(d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터 작업\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
